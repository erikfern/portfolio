<!DOCTYPE html>
<html>
<head>
	<link rel="stylesheet" type="text/css" href="style.css">
	<link href="https://fonts.googleapis.com/css?family=Montserrat:300,400&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Lato:300&display=swap" rel="stylesheet">
  
	<title>Portfolio - Erik Fernandez</title>
</head>
<body>
  <div class="navbar">
    <h1 class="site-title">ERIK FERNANDEZ</h1>
    <h2 class="sub-title">Portfolio</h2>
  </div>
	<div class="artwork-detailed-text">
  	<h1 class="artwork-detailed-title">A STORY ABOUT TAP DANCING IN AUGMENTED REALITY</h1>
  	<h2 class="artwork-detailed-date">2019</h2>
  	<div class="artwork-detailed-desc">
    	<P>
    		This group project is a final assignment for York University's course from the Digital Media program, DATT 3930: Screen-Based Fluid Interfaces. We are tasked to create a narrative around a pair of tap shoes were while also implementing a solution to create 3D objects in the AR space without the use of markers.
    	</P>

    	<p>
    		Our narrative is about showing the declining popularity of tap dancing by comparing tap dancing videos from the previous century to this century. In the set of videos, the production values were shown to be higher during the 1900s but have less video quality, while videos in the 2000s were shown to have less production value but have higher video quality. The second part of our story was about how our group can take part in the tap dancing culture by sharing this AR app with others, and how these users can also participate in the culture by simply using the app's interactive features.
    	</p>

    	<p>
    		Using Unity and the Vuforia engine to enable Augmented Reality functionalities, we created mobile app that generates a 3D rendering of a pair of tap shoes and six 2D planes above it with each one playing tap dancing videos from different time periods upon detecting the appropriate AR marker. Utilizing Vufora's ground plane detection feature, the app also generated footprints with slight variations in their angles when the user pointed to the floor and tapped their screen to emulate dancing.
    	</p>

    	<p>
    		My contribution for this project is to find a solution to generate 3D objects without the use of AR markers and weaving that system into the narrative (i.e. the footprints). It involves researching the capabilities of AR technology, and understanding how to use certain features provided by the Vuforia engine.
    	</p>
  	</div>
	</div>
	<div class="artwork-detailed-pic-container">
  	<img class="artwork-detailed-pic" id="larger-img" src="website-media/tap-shoe-ar.png">
  	<iframe src="https://player.vimeo.com/video/383213284?title=0&byline=0&portrait=0" width="400" height="743" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>
	</div>
</body>
</html>