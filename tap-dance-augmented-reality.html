<!DOCTYPE html>
<html>
<head>
	<link rel="stylesheet" type="text/css" href="style.css">
	<link href="https://fonts.googleapis.com/css?family=Montserrat:300,400&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Lato:400&display=swap" rel="stylesheet">
  
	<title>Portfolio - Erik Fernandez</title>
</head>
<body>
  <div class="navbar">
    <h1 class="site-title">ERIK FERNANDEZ</h1>
    <h2 class="sub-title">Portfolio</h2>
  </div>
	<div class="artwork-detailed-text">
  	<h1 class="artwork-detailed-title">A STORY ABOUT TAP DANCING IN AUGMENTED REALITY</h1>
  	<h2 class="artwork-detailed-date">2019</h2>
  	<div class="artwork-detailed-desc">

      <p>Project folder: <a href="https://www.dropbox.com/s/slklgwjo03mdhsc/Vuforia-tap-shoes-plane-AR.zip?dl=0">https://www.dropbox.com/s/slklgwjo03mdhsc/Vuforia-tap-shoes-plane-AR.zip?dl=0</a></p>

    	<P>
    		This group project is a final assignment for York University's course from the Digital Media program, DATT 3930: Screen-Based Fluid Interfaces. We are tasked to create a narrative around a pair of tap shoes were while also implementing a solution to create 3D objects in the AR space without the use of markers.
    	</P>

    	<p>
    		Our narrative is about showing the declining popularity of tap dancing by comparing tap dancing videos from the previous century to this century. In the set of videos, the production values are higher during the 1900s but have less video quality, while videos in the 2000s have less production value but have higher video quality. The second part of our story is about how our current generation can take part in the tap dancing culture with the help of technology. Users can lay virtual footprints on the floor through the app, imitating tap dancing, by tapping on the screen.
    	</p>

    	<p>
    		Using Unity and the Vuforia engine to enable Augmented Reality functionalities, this mobile app generates a pair virtual tap shoes and six 2D planes above it once the AR marker is detected. The 2D planes play tap dancing videos from different time periods. Utilizing Vufora's ground plane detection feature, the user can generate footprints on the floor by tapping the screen.
    	</p>

    	<p>
    		My contribution for this project is to find a solution to generate 3D objects without the use of AR markers and weaving that system into the narrative (i.e. the footprints). It involves researching the capabilities of AR technology, and understanding how to use certain features provided by the Vuforia engine.
    	</p>
  	</div>
	</div>
	<div class="artwork-detailed-pic-container">
  	<img class="artwork-detailed-pic" id="larger-img" src="website-media/tap-shoe-ar.png">
  	<iframe src="https://player.vimeo.com/video/383213284?title=0&byline=0&portrait=0" width="400" height="743" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>
	</div>
</body>
</html>